import cv2
import time
import pickle
import numpy as np
import paho.mqtt.client as mqtt
import insightface
import json
import os
import subprocess
from datetime import datetime, timedelta
from threading import Thread
cv2.startWindowThread()
# ========== RTSP å¤šåŸ·è¡Œç·’è®€å– ==========
class FFmpegRTSPStream:
    def __init__(self, rtsp_url, width=1280, height=720):
        print("1-1")
        self.rtsp_url = rtsp_url
        self.width = width
        self.height = height
        self.frame_size = width * height * 3  # bgr24
        self.process = None
        self.frame = None
        self.stopped = False
        self.thread = Thread(target=self.update, daemon=True)
        self.restart()  # åˆæ¬¡å•Ÿå‹•
        self.thread.start()
        print("1-2")

    def restart(self):
        print("1-3")
        if self.process:
            self.process.kill()
            self.process.stdout.close()
        ffmpeg_cmd = [
            "ffmpeg",
            "-rtsp_transport", "udp",
            "-i", self.rtsp_url,
            "-vf", "fps=15,scale=1280:720",   # â† åŠ å…¥é™åˆ¶å¹€ç‡èˆ‡ç¸®æ”¾è§£æåº¦
            "-f", "rawvideo",
            "-pix_fmt", "bgr24",
            "-an", "-sn",
            "-fflags", "nobuffer",
            "-flags", "low_delay",
            "-probesize", "32",
            "-analyzeduration", "0",
            "-loglevel", "quiet",
            "-"
        ]
        print("1-4")
        self.process = subprocess.Popen(ffmpeg_cmd, stdout=subprocess.PIPE, bufsize=10**8)
        print("ğŸ” FFmpeg å·²å•Ÿå‹•")

    def update(self):
        missed_count = 0
        while not self.stopped:
            try:
                raw_frame = self.process.stdout.read(self.frame_size)
                if len(raw_frame) != self.frame_size:
                    missed_count += 1
                    if missed_count > 10:
                        print("âš ï¸ FFmpeg frame ä¸è¶³ï¼Œè‡ªå‹•é‡å•Ÿ")
                        self.restart()
                        missed_count = 0
                    time.sleep(0.2)
                    continue
                frame = np.frombuffer(raw_frame, np.uint8).reshape((self.height, self.width, 3))
                self.frame = frame
                missed_count = 0
            except Exception as e:
                print(f"âŒ FFmpeg frame è®€å–å¤±æ•—: {e}")
                self.restart()
                time.sleep(1)

    def read(self):
        return self.frame

    def stop(self):
        print("4")
        self.stopped = True
        self.thread.join()
        print("5")
        if self.process:
            self.process.kill()
            self.process.stdout.close()
        print("6")

# ========== MQTT è¨­å®š ==========
MQTT_BROKER = "120.118.142.140"
MQTT_PORT = 1883
MQTT_USER = "ip"
MQTT_PASS = "etc7337383"
MQTT_TOPIC_CARD = "new_record"
MQTT_TOPIC_STATUS = "face_IP"
ROOM_NAME = "IP"

# ========== åˆ¤æ–·æ˜¯å¦ç‚ºæ­£é¢è‡‰ ==========
def is_frontal_face(kps, max_eye_diff_ratio=0.2, max_nose_offset_ratio=0.2):
    left_eye, right_eye, nose, left_mouth, right_mouth = kps
    eye_y_diff = abs(left_eye[1] - right_eye[1])
    eye_dist = np.linalg.norm(left_eye - right_eye)
    eye_y_ratio = eye_y_diff / eye_dist
    eye_mid_x = (left_eye[0] + right_eye[0]) / 2
    nose_offset = abs(nose[0] - eye_mid_x)
    nose_offset_ratio = nose_offset / eye_dist
    return (eye_y_ratio < max_eye_diff_ratio) and (nose_offset_ratio < max_nose_offset_ratio)

# ========== åˆå§‹åŒ–æ¨¡å‹èˆ‡ä¸²æµ ==========
def init_face_analysis():
    app = insightface.app.FaceAnalysis(name="buffalo_l")
    app.prepare(ctx_id=0)
    return app

# ========== è¼‰å…¥ face_db ==========
with open("face_db.pkl", "rb") as f:
    face_db = pickle.load(f)

# ========== MQTT ==========
def safe_publish(topic, payload, retry=3):
    for _ in range(retry):
        result = mqtt_client.publish(topic, payload)
        if result.rc == 0:
            return True
        time.sleep(0.2)
    print(f"âŒ MQTT ç™¼é€å¤±æ•—ï¼Œtopic = {topic}")
    return False

# ========== åˆå§‹åŒ– MQTT ==========
mqtt_client = mqtt.Client()
mqtt_client.username_pw_set(MQTT_USER, MQTT_PASS)
mqtt_client.connect(MQTT_BROKER, MQTT_PORT, 60)

# ========== RTSP è¨­å®š ==========
RTSP_URL = "rtsp://etc000:Mor35473!@192.168.0.220:554/stream1"
os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = "rtsp_transport;tcp|buffer_size;4096"

cap = FFmpegRTSPStream(RTSP_URL)
app = init_face_analysis()

# ========== ç‹€æ…‹è®Šæ•¸ ==========
THRESHOLD = 0.5
last_found = None
last_valid_time = 0
last_reset_time = datetime.now()
frame_count = 0
door_open = False  # ğŸšª æ§åˆ¶é–€é–‹å•Ÿç‹€æ…‹
consecutive_none_count = 0  # â±ï¸ RTSP é€¾æ™‚è¨ˆæ•¸å™¨
RECONNECT_THRESHOLD = 50    # â±ï¸ é€£çºŒå¤±æ•— 50 æ¬¡ï¼ˆç´„ 3 ç§’ï¼‰å°±é‡é€£

print("ğŸš€ é–‹å§‹è¾¨è­˜ä¸­... æŒ‰ Ctrl+C çµæŸ")

try:
    while True:
        now = datetime.now()
        mqtt_client.loop(timeout=0.1)
        # ========== è¶…æ™‚è‡ªå‹•é—œé–€ ==========
        if door_open and (time.time() - last_valid_time > 5):
            mqtt_client.publish(MQTT_TOPIC_STATUS, 'off')
            print(f"ğŸ“¤ ç™¼é€ MQTT: topic = {MQTT_TOPIC_STATUS} â†’ off")
            last_found = None
            door_open = False

        # ========== æ¯å°æ™‚é‡å•Ÿæ¨¡å‹èˆ‡ä¸²æµ ==========
        if now - last_reset_time > timedelta(hours=1):
            print("ğŸ”„ ä¸€å°æ™‚å·²åˆ°ï¼Œè‡ªå‹•é‡‹æ”¾ä¸¦é‡å•Ÿ RTSP èˆ‡æ¨¡å‹")
            try:
                cap.stop()
            except Exception as e:
                print(f"âš ï¸ cap.stop() å¤±æ•—: {e}")
            time.sleep(5)
            print("1")
            cap = FFmpegRTSPStream(RTSP_URL)  # â† é‡æ–°å»ºç«‹æ–°ç‰©ä»¶
            print("2")
            app = init_face_analysis()
            print("3")
            last_reset_time = now
            print("âœ… é‡å•Ÿå®Œæˆ")


        # ========== è®€å–å½±åƒ ==========
        frame = cap.read()
        if frame is None:
            consecutive_none_count += 1
            if consecutive_none_count >= RECONNECT_THRESHOLD:
                print("âš ï¸ RTSP é€£çºŒè®€å–å¤±æ•—ï¼Œè‡ªå‹•é‡å•Ÿä¸²æµ...")
                cap.stop()
                time.sleep(1)
                cap = FFmpegRTSPStream(RTSP_URL)
                consecutive_none_count = 0
                print("âœ… ä¸²æµé‡å•Ÿå®Œæˆ")
            continue
        else:
            consecutive_none_count = 0  # æˆåŠŸè®€å– â†’ é‡ç½®è¨ˆæ•¸å™¨

        frame_count += 1

        # æ¯3å¹€åªé¡¯ç¤ºï¼Œä¸åšè¾¨è­˜ï¼ˆé™è² è¼‰ï¼‰
        if frame_count % 5 != 0:
            if frame is not None and frame.shape == (720, 1280, 3):
                cv2.imshow("Face Recognition", frame)
            else:
                print("âš ï¸ ç„¡æ•ˆçš„ frameï¼Œè·³éé¡¯ç¤º")
            key = cv2.waitKey(1)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
            continue

        # ========== é–€é–‹å•Ÿä¸­ï¼Œè·³éè¾¨è­˜ ==========
        if door_open:
            frame = frame.copy()
            cv2.putText(frame, "é–€å·²é–‹å•Ÿä¸­...", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
            if frame is not None and frame.shape == (720, 1280, 3):
                cv2.imshow("Face Recognition", frame)
            else:
                print("âš ï¸ ç„¡æ•ˆçš„ frameï¼Œè·³éé¡¯ç¤º")
            key = cv2.waitKey(1)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
            time.sleep(0.2)
            continue

        # ========== è‡‰éƒ¨è¾¨è­˜ ==========
        found = None
        faces = app.get(frame)

        if faces:
            faces = sorted(faces, key=lambda f: (f.bbox[2] - f.bbox[0]) * (f.bbox[3] - f.bbox[1]), reverse=True)
            for face in faces:
                x1, y1, x2, y2 = map(int, face.bbox)
                width = x2 - x1
                height = y2 - y1
                if width < 60 or height < 80:
                    continue
                if not is_frontal_face(face.kps):
                    continue

                frame_ori = frame.copy()
                emb = face.embedding / np.linalg.norm(face.embedding)
                best_match = None
                best_score = 0
                
                for name, ref_emb_list in face_db.items():
                    for ref_emb in ref_emb_list:
                        sim = np.dot(emb, ref_emb / np.linalg.norm(ref_emb))  # ç¢ºä¿å·²æ­£è¦åŒ–
                        if sim > best_score:
                            best_score = sim
                            best_match = name
                
                if best_score > THRESHOLD:
                    found = best_match
                else:
                    found = None

        # ========== ç‹€æ…‹æ”¹è®Šæ‰è§¸ç™¼å‹•ä½œ ==========
        if found and found != last_found:
            frame = frame.copy()
            # æ¨™ç¤º + å„²å­˜å½±åƒ
            x1, y1, x2, y2 = map(int, face.bbox)
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, found, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

            timestamp = now.strftime("%Y%m%d%H%M%S")
            save_dir = "captures"
            os.makedirs(save_dir, exist_ok=True)
            cv2.imwrite(os.path.join(save_dir, f"{found}_{timestamp}_ori.jpg"), frame_ori)
            cv2.imwrite(os.path.join(save_dir, f"{found}_{timestamp}_mem.jpg"), frame)

            # ç™¼é€ MQTT
            payload_card = {
                "room": ROOM_NAME,
                "card": found,
                "auth": True
            }
            safe_publish(MQTT_TOPIC_STATUS, 'on')
            safe_publish(MQTT_TOPIC_CARD, json.dumps(payload_card, separators=(',', ':')))

            print(f"ğŸ“¤ ç™¼é€ MQTT: topic = {MQTT_TOPIC_CARD}")
            print(f"ğŸ“¦ payload = {json.dumps(payload_card, ensure_ascii=False)}")
            print(f"ğŸ“¤ ç™¼é€ MQTT: topic = {MQTT_TOPIC_STATUS} â†’ on")

            last_found = found
            last_valid_time = time.time()
            door_open = True

        # ========== é¡¯ç¤ºç•«é¢ ==========
        if frame is not None and frame.shape == (720, 1280, 3):
            cv2.imshow("Face Recognition", frame)
        else:
            print("âš ï¸ ç„¡æ•ˆçš„ frameï¼Œè·³éé¡¯ç¤º")
        key = cv2.waitKey(1)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

        time.sleep(0.2)

except KeyboardInterrupt:
    print("ğŸ›‘ çµæŸè¾¨è­˜")

finally:
    cap.stop()
    cv2.destroyAllWindows()
